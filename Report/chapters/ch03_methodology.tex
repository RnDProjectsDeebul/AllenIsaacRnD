%!TEX root = ../report.tex
\documentclass[report.tex]{subfiles}
\begin{document}
    \chapter{Methodology}

    How you are planning to test/compare/evaluate your research.
    Criteria used.
    


    \section{Experimental Setup}
    \begin{itemize}
        \item On YCBV test dataset available in BOP format.
        \item On the YCB dataset generated using blenderproc.
        \item On Kinova robotic arm for object pose detection.
        \begin{itemize}
        \item How is data passed into the SLAM algorithm?
        \item How is the output processed?
        \item Metrics used for testing and comparison.
    \end{itemize}
    \end{itemize}
        \begin{itemize}
\item Below mentioned are some of the publicly available dataset for the usecase.
\begin{itemize}
    \item TUM RGBD dataset\cite{rgbd} - ground truth odom, RGB image, depth image and accelerometer data are available. Can be used for trajectory error measurement.(\href{https://cvg.cit.tum.de/data/datasets/rgbd-dataset/download}{here})
    \item BOP dataset - ground truth camera pose, RGB image, depth image, ground truth object poses, object bounding boxes.(\href{https://bop.felk.cvut.cz/datasets/)}{here})
\end{itemize}
\end{itemize}

    \section{Evaluation metrics}
    \begin{itemize}

\item Below mentioned are some of the evaluation metrics to test the \textbf{object pose errors}.
\begin{itemize}
    \item \textbf{Centroid error} - Measures the Euclidean distance between the actual object centroid and the estimated quadric centroid. For each object, this could be individually calculated to identify which has max and which has min deviation among all. Also, it can be calculated as the root mean square deviation of the estimated object centroid from the ground truth object centroid for all the objects. $\operatorname{RMSE} E_{\mathrm{cen}}=\frac{1}{n} \sum_{i=1}^{n} \sqrt{\left\|\mathbf{q}_{j}^{\mathrm{t}}-\hat{\mathbf{q}}_{j}^{\mathrm{t}}\right\|^{2}}$. The estimated centroid can be derived from the 3 elements of the last column of the dual quadric representation matrix of size 4x4.\cite{sünderhauf2017dual}
    \item \textbf{Rotation error} - Measured as the angle between the rotation matrixes of ground truth and estimated object pose represented in unit quaternion format. This can be done by performing dot product operation on these quaternions and then converting it to angular format in radians.
    \item \textbf{Volume error} - Measures the difference between the actual ground truth volume of the object and the estimated volume of the object by comparing the overlapping between them. To compute the actual volume of the object, we may need to use the available 3D cuboid representation of the ground truth objects. Then we need to perform Monte Carlo sampling to randomly sample points within the ground truth 3D cuboid and check how many of them lie within the estimated ellipsoid to get an idea of the overlapping percentage. Even though it may not give the exact quantity of the error, it can still represent the volume error which should be as low as possible.
\end{itemize}

\item Below mentioned are some of the evaluation metrics to test the \textbf{camera pose or trajectory errors}.
\begin{itemize}
    \item \textbf{Trajectory deviation error} - Measures the 3D position error of the estimated trajectory and the actual trajectory. It can be calculated as root mean square deviation of the estimated pose from the ground truth pose. $\mathrm{RMSE} \mathrm{pos}_{\mathrm{pos}}=\frac{1}{n} \sum_{i=1}^{n} \sqrt{\left\|\mathbf{x}_{i}^{x, y, z}-\hat{\mathbf{x}}_{i}^{x, y, z}\right\|^{2}}$. If the robot is moving in a plane, we can assume z=0\cite{sünderhauf2017dual}. We can get the max and min deviation in the estimated trajectory from the ground truth trajectory along with the plot for deviation for each camera frame. Also, the root mean square deviation is computed.
    \item \textbf{Rotation error} - Same metrics definition as that of rotation error in object pose error evaluation metric. We can plot the angular deviation plot for each camera frame. Average rotational error is computed.
    \item \textbf{Trajectory similarity measurements} - Given a set of 3D points of the ground truth and the estimated trajectories, we can perform the similarity checking of those trajectories using Procrustes Analysis, Fréchet Distance, Chamfer Distance.
\end{itemize}

\item Below mentioned are some of the evaluation metrics to test the \textbf{object initialization errors}.
\begin{itemize}
    \item \textbf{Uninitiated objects error} - This error is measured in terms of integer numbers which indicate how many objects in the environment were not mapped by the Quadric SLAM approach.
    \item \textbf{Association error} - This error is also estimated in integers where it indicates the number of wrong associations of objects.
    \item \textbf{Duplication error} - Measured in integers where it counts how many copies of the objects in the real world are duplicated in the created map.
\end{itemize}

\item Trajectory error is mentioned as trajectory quality and Centroid \& volume error are mentioned as landmark quality evaluation metrics in the main paper\cite{sünderhauf2017dual}.
\item Metrics such as centroid error, volume error, uninitiated objects error and orientation error as Match factor are mentioned in the master thesis by Kamil Kaminski\cite{dataassosciation}.


\item Below mentioned are some of the metrics to compare the \textbf{performance} of different object-oriented SLAMs.
\begin{itemize}
    \item \textbf{Size of stored map} - to compare how much space is needed to store the map containing the objects. 
    \item \textbf{Computational power needed} - This can be measured based on CPU, GPU, RAM usage system profile.
    \item \textbf{Computation time} - How much time is required for a single step in the SLAM. That is, taking the image input and updating the internal parameters. Overall computation time and time taken for each functional block in the SLAM needs to be identified to check which operation consumes more time.
\end{itemize}
\end{itemize}
\end{document}
