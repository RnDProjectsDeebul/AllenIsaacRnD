{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e56c381",
   "metadata": {},
   "source": [
    "**Given the path to the folder containing all the datasets(dataset_path), this script will align the slam output with the ground truth and perform the error metrics estimation and generate a file containing the error metrics.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fdf547",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af4b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import math\n",
    "from matplotlib.patches import Patch\n",
    "from distinctipy import get_colors # to get unique colors\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from itertools import product\n",
    "from numpy.linalg import LinAlgError, eigvalsh\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# save matplotlib plots without displaying\n",
    "%matplotlib agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa695ae3",
   "metadata": {},
   "source": [
    "# Global Data and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b58356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOP YCBV dataset\n",
    "dataset_info = {'1': 'master_chef_can',\n",
    "                '2': 'cracker_box',\n",
    "                '3': 'sugar_box',\n",
    "                '4': 'tomato_soup_can',\n",
    "                '5': 'mustard_bottle',\n",
    "                '6': 'tuna_fish_can',\n",
    "                '7': 'pudding_box',\n",
    "                '8': 'gelatin_box',\n",
    "                '9': 'potted_meat_can',\n",
    "                '10': 'banana',\n",
    "                '11': 'pitcher_base',\n",
    "                '12': 'bleach_cleanser',\n",
    "                '13': 'bowl',\n",
    "                '14': 'mug',\n",
    "                '15': 'power_drill',\n",
    "                '16': 'wood_block',\n",
    "                '17': 'scissors',\n",
    "                '18': 'large_marker',\n",
    "                '19': 'large_clamp',\n",
    "                '20': 'extra_large_clamp',\n",
    "                '21': 'foam_brick'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e897a",
   "metadata": {},
   "source": [
    "## Function to plot ellipsoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833d60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference - https://github.com/qcr/quadricslam/blob/master/src/quadricslam/visualisation.py\n",
    "def plot_ellipsoid(pose: np.ndarray, radii: np.ndarray, ax: matplotlib.figure.Axes, color):\n",
    "    # Generate ellipsoid of appropriate size at origin\n",
    "    SZ = 50\n",
    "    radii = np.abs(radii)\n",
    "    u, v = np.linspace(0, 2 * np.pi, SZ), np.linspace(0, np.pi, SZ)\n",
    "    x, y, z = (radii[0] * np.outer(np.cos(u), np.sin(v)),\n",
    "               radii[1] * np.outer(np.sin(u), np.sin(v)),\n",
    "               radii[2] * np.outer(np.ones_like(u), np.cos(v)))\n",
    "\n",
    "    # Rotate the ellipsoid, then translate to centroid\n",
    "    ps = pose @ np.vstack([\n",
    "        x.reshape(-1),\n",
    "        y.reshape(-1),\n",
    "        z.reshape(-1),\n",
    "        np.ones(z.reshape(-1).shape)\n",
    "    ])\n",
    "\n",
    "    # Plot the ellipsoid\n",
    "    ax.plot_wireframe(\n",
    "        ps[0, :].reshape(SZ, SZ),\n",
    "        ps[1, :].reshape(SZ, SZ),\n",
    "        ps[2, :].reshape(SZ, SZ),\n",
    "        rstride=4,\n",
    "        cstride=4,\n",
    "        color=color,\n",
    "        linewidth=0.5,\n",
    "    )## Function to plot ellipsoids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f27764",
   "metadata": {},
   "source": [
    "## Function to plot cuboids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7afd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cuboid(pose: np.ndarray, size: np.ndarray, ax: matplotlib.figure.Axes, color):\n",
    "    # Get all 8 corner points of the cuboid\n",
    "    #vertices = np.array(list(product(*zip(pose[:3, -1] - 0.5 * size, pose[:3, -1] + 0.5 * size))))\n",
    "    vertices = np.array(list(product(*zip(- 0.5 * size, + 0.5 * size))))\n",
    "    \n",
    "    # Transform the cuboid's vertices using the pose matrix\n",
    "    t_vertices = np.dot(pose[:3, :3], vertices.T).T + pose[:3, -1]\n",
    "    \n",
    "    # Define the edges of the cuboid using the vertices\n",
    "    edges = [\n",
    "        [t_vertices[0], t_vertices[1]], [t_vertices[1], t_vertices[5]], [t_vertices[5], t_vertices[4]],\n",
    "        [t_vertices[4], t_vertices[0]], [t_vertices[7], t_vertices[6]], [t_vertices[6], t_vertices[2]],\n",
    "        [t_vertices[2], t_vertices[3]], [t_vertices[3], t_vertices[7]], [t_vertices[0], t_vertices[2]],\n",
    "        [t_vertices[1], t_vertices[3]], [t_vertices[4], t_vertices[6]], [t_vertices[5], t_vertices[7]]\n",
    "    ]\n",
    "    \n",
    "    ax.add_collection3d(Line3DCollection(edges, colors=color, linewidths=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14954b12",
   "metadata": {},
   "source": [
    "## Function to plot trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbf0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traj(data: List, ax: matplotlib.figure.Axes, length = 50, c:str = 'cyan', label = None):\n",
    "    \n",
    "    # to plot trajectory\n",
    "    traj = []\n",
    "    \n",
    "    for idx in range(len(data)):\n",
    "        # position\n",
    "#         ax.scatter(data[idx][0,-1], data[idx][1,-1], data[idx][2,-1], c='r', marker='*')\n",
    "        # orientation\n",
    "        if idx % 30 == 0:\n",
    "            # X\n",
    "            ax.quiver(data[idx][0,-1], data[idx][1,-1], data[idx][2,-1],\n",
    "                      data[idx][0, 0], data[idx][1, 0], data[idx][2, 0],\n",
    "                      color='r', length=length, linewidth=0.2, alpha=1)\n",
    "            # Y\n",
    "            ax.quiver(data[idx][0,-1], data[idx][1,-1], data[idx][2,-1],\n",
    "                      data[idx][0, 1], data[idx][1, 1], data[idx][2, 1],\n",
    "                      color='g', length=length, linewidth=0.2, alpha=1)\n",
    "            # Z\n",
    "            ax.quiver(data[idx][0,-1], data[idx][1,-1], data[idx][2,-1],\n",
    "                      data[idx][0, 2], data[idx][1, 2], data[idx][2, 2],\n",
    "                      color='b', length=length, linewidth=0.2, alpha=1)\n",
    "        \n",
    "        traj.append([data[idx][0,-1], data[idx][1,-1], data[idx][2,-1]])\n",
    "        \n",
    "    #trajectory\n",
    "    if c != 'cyan':\n",
    "        traj = np.array(traj)\n",
    "        if label==None:\n",
    "            ax.plot(traj[:, 0], traj[:, 1], traj[:, 2], color=c)\n",
    "        else:\n",
    "            ax.plot(traj[:, 0], traj[:, 1], traj[:, 2], color=c, label = label)\n",
    "        \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca012357",
   "metadata": {},
   "source": [
    "# Functions for Error Calculation of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cd7a9",
   "metadata": {},
   "source": [
    "### Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695e8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given 2 centroids, it will output the euclidean distance between the 2 points\n",
    "def euclidean_distance(centroid1, centroid2):\n",
    "    return np.linalg.norm(centroid1 - centroid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e6d09",
   "metadata": {},
   "source": [
    "### Rotation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16812f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rotation matrix to quaternion conversion\n",
    "def matrix_to_quaternion(matrix):\n",
    "    # Extract the 3x3 rotation matrix from the 4x4 transformation matrix\n",
    "    rotation_matrix = matrix[:3, :3]\n",
    "\n",
    "    # Ensure the rotation matrix is orthogonal (if necessary)\n",
    "    if not np.allclose(np.linalg.det(rotation_matrix), 1.0):\n",
    "        rotation_matrix = rotation_matrix / np.cbrt(np.linalg.det(rotation_matrix))\n",
    "\n",
    "    # Create a Rotation object from the rotation matrix\n",
    "    rotation = Rotation.from_matrix(rotation_matrix)\n",
    "\n",
    "    # Get the quaternion representation\n",
    "    quaternion = rotation.as_quat()\n",
    "\n",
    "    return quaternion\n",
    "\n",
    "\n",
    "## quaternion representation of the rotation matrix as input\n",
    "def rotation_error_quaternion(quat1, quat2):\n",
    "    r1 = Rotation(quat1)\n",
    "    r2 = Rotation(quat2)\n",
    "\n",
    "    # Convert to unit quaternions if necessary\n",
    "    if not np.isclose(np.linalg.norm(r1.as_quat()), 1.0):\n",
    "        r1 = r1.normalized()\n",
    "    if not np.isclose(np.linalg.norm(r2.as_quat()), 1.0):\n",
    "        r2 = r2.normalized()\n",
    "    # Compute the rotation error (angle between the quaternions)\n",
    "    error_angle = 2.0 * np.arccos(np.abs(np.dot(r1.as_quat(), r2.as_quat())))\n",
    "    return error_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecb903",
   "metadata": {},
   "source": [
    "### Procrustes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc8ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes_analysis(points1, points2):\n",
    "    set1, set2, disparity = procrustes(points1, points2)\n",
    "    return set1, set2, disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d71601",
   "metadata": {},
   "source": [
    "### Fréchet Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908a7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frechet_distance(curve1, curve2):\n",
    "    \n",
    "    # Compute the directed Hausdorff distance (equivalent to Fréchet Distance)\n",
    "    distance_1_to_2, _, _ = directed_hausdorff(curve1, curve2)\n",
    "    distance_2_to_1, _, _ = directed_hausdorff(curve2, curve1)\n",
    "\n",
    "    # Return the maximum of the two directed Hausdorff distances (Fréchet Distance)\n",
    "    frechet_distance = max(distance_1_to_2, distance_2_to_1)\n",
    "    return frechet_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7091593",
   "metadata": {},
   "source": [
    "### Chamfer Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93c4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfer_distance(point_cloud1, point_cloud2):\n",
    "    return np.mean(np.min(cdist(point_cloud1, point_cloud2),axis=0)) + np.mean(np.min(cdist(point_cloud2, point_cloud1), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd3323",
   "metadata": {},
   "source": [
    "### Percentage of Intersection Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "912b54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate points within GT cuboid\n",
    "def generate_points_within_cuboid(centroid, dimensions, rotation_matrix, num_points=1000):\n",
    "    # Extract centroid coordinates\n",
    "    cx, cy, cz = centroid\n",
    "    \n",
    "    # Extract dimensions of the cuboid\n",
    "    Lx, Ly, Lz = dimensions\n",
    "    \n",
    "    # Generate random points within the unit cube\n",
    "    points_in_unit_cube = np.random.rand(num_points, 3)\n",
    "    \n",
    "    # Scale and translate points to fit within the cuboid\n",
    "    points_in_cuboid = points_in_unit_cube * np.array([Lx, Ly, Lz]) - np.array([Lx / 2, Ly / 2, Lz / 2])\n",
    "    \n",
    "    # Apply the rotation to the points\n",
    "    rotated_points = np.dot(points_in_cuboid, rotation_matrix.T)\n",
    "    \n",
    "    # Translate the points to the cuboid centroid\n",
    "    translated_points = rotated_points + np.array([cx, cy, cz])\n",
    "    \n",
    "    return translated_points\n",
    "\n",
    "# function to check if the point lies within the ellipsoid\n",
    "def is_point_inside_ellipsoid(point, centroid, radii, rotation_matrix):\n",
    "    # Convert the point to the ellipsoid's local coordinate system\n",
    "    local_point = point - centroid\n",
    "\n",
    "    # Apply the inverse rotation to bring the point to the ellipsoid's local orientation\n",
    "    local_point_rotated = np.dot(rotation_matrix.T, local_point)\n",
    "\n",
    "    # Normalize the point by dividing its coordinates by the semi-axes lengths of the ellipsoid\n",
    "    normalized_point = local_point_rotated / radii\n",
    "\n",
    "    # Check if the normalized point lies within the unit sphere\n",
    "    return np.linalg.norm(normalized_point) <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927775e",
   "metadata": {},
   "source": [
    "### Rotation Error Correction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48c4398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_to_closest_multiple_of_90(number):\n",
    "    # Calculate the remainder when dividing the number by 90\n",
    "    remainder = number % 90\n",
    "    \n",
    "    # Determine whether to round up or down based on the remainder\n",
    "    if remainder < 45:\n",
    "        return number - remainder\n",
    "    else:\n",
    "        return number + (90 - remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab950acf",
   "metadata": {},
   "source": [
    "# Function for Postprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1c68210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset -> path to the dataset folder\n",
    "# plottings -> the bool that controls the plots to be saved or not\n",
    "# batch -> if batch, then read the batch output file\n",
    "def postprocessing(dataset:str, plottings:bool, batch:bool):\n",
    "    \n",
    "    # directory to save images\n",
    "    if batch:\n",
    "        images_save_directory = os.path.join(dataset, 'quadric_slam_result/images_batch')\n",
    "    else:\n",
    "        images_save_directory = os.path.join(dataset, 'quadric_slam_result/images_incre')\n",
    "    if not os.path.exists(images_save_directory):\n",
    "        os.makedirs(images_save_directory)\n",
    "    \n",
    "    \n",
    "    ################# GROUND TRUTH CAMERA POSE #################\n",
    "    ## reading the ground truth scene_camera.json file\n",
    "    f = open(dataset + '/scene_camera.json')\n",
    "    camera_pose = json.load(f)\n",
    "    \n",
    "    ## used for plotting\n",
    "    x_min = 0\n",
    "    x_max = 0\n",
    "    y_min = 0\n",
    "    y_max = 0\n",
    "    z_min = 0\n",
    "    z_max = 0\n",
    "    \n",
    "    ## The camera poses are in the format w2c(World with respect to camera)\n",
    "    ## We need c2w(Camera with respect to world)\n",
    "    \n",
    "    gt_traj = [] ## to store the c2w as 4x4 numpy arrays within a list \n",
    "\n",
    "    for c in camera_pose:\n",
    "        \n",
    "        # converting from json raw format to a numpy array\n",
    "        world2camera = np.column_stack((np.array(camera_pose[c]['cam_R_w2c']).reshape(3,3),\n",
    "                                        np.array(camera_pose[c]['cam_t_w2c']).reshape(3,1)))\n",
    "        world2camera = np.row_stack((world2camera, np.array([0. , 0., 0., 1.])))\n",
    "\n",
    "        # In the dataset, the transformation is w2c(world with respect to the camera)\n",
    "        # we need to change it to camera with respect to the world.\n",
    "        corrected_pose = np.linalg.inv(world2camera)\n",
    "        gt_traj.append(corrected_pose)\n",
    "        \n",
    "        x_min = min(x_min, corrected_pose[0,-1])\n",
    "        x_max = max(x_max, corrected_pose[0,-1])\n",
    "        y_min = min(y_min, corrected_pose[1,-1])\n",
    "        y_max = max(y_max, corrected_pose[1,-1])\n",
    "        z_min = min(z_min, corrected_pose[2,-1])\n",
    "        z_max = max(z_max, corrected_pose[2,-1])\n",
    "    ################# GROUND TRUTH CAMERA POSE #################\n",
    "    \n",
    "    \n",
    "    ################# GROUND TRUTH OBJECT POSE #################\n",
    "    ## reading the ground truth scene_gt.json file\n",
    "    f = open(dataset + '/scene_gt.json')\n",
    "    object_pose = json.load(f)\n",
    "    \n",
    "    ## Loading ground truth obejct models and assigning colors\n",
    "    f = open(os.path.dirname(dataset) + '/models_info.json')\n",
    "    model_data = json.load(f)\n",
    "\n",
    "    classes = [] ## which all classes are present in the current datset\n",
    "\n",
    "    for o in range(len(object_pose['1'])):\n",
    "        classes.append(object_pose['1'][o]['obj_id'])\n",
    "    \n",
    "    # get unique colors for each class\n",
    "    colors = get_colors(len(object_pose['1']))    \n",
    "    \n",
    "    # to store all object poses\n",
    "    gt_pose_data_all = [[] for _ in range(len(object_pose['1']))]\n",
    "\n",
    "    idx = 0\n",
    "    for c in camera_pose:\n",
    "\n",
    "        for o in range(len(object_pose['1'])):\n",
    "\n",
    "            object2camera = np.column_stack((np.array(object_pose[c][o]['cam_R_m2c']).reshape(3,3),\n",
    "                                             np.array(object_pose[c][o]['cam_t_m2c']).reshape(3,1)))\n",
    "            object2camera = np.row_stack((object2camera, np.array([0. , 0., 0.,1.])))\n",
    "\n",
    "            # given W with respect to C and M with respect to C\n",
    "            # We need M with respect to W. In other words,\n",
    "            # we need W_T_M = inv(C_T_W) @ C_T_M = W_T_C @ C_T_M \n",
    "            gt_pose_data_all[o].append(np.dot(gt_traj[idx], object2camera))\n",
    "\n",
    "        idx+=1\n",
    "    \n",
    "    # averaging and getting a single position for the object pose\n",
    "    gt_pose = [] # to store the pose of each object\n",
    "\n",
    "    for obj in gt_pose_data_all:\n",
    "        arrays_stack = np.stack(obj)\n",
    "        averaged_pose = np.mean(arrays_stack, axis=0)\n",
    "        gt_pose.append(averaged_pose)\n",
    "        \n",
    "        x_min = min(x_min, averaged_pose[0,-1])\n",
    "        x_max = max(x_max, averaged_pose[0,-1])\n",
    "        y_min = min(y_min, averaged_pose[1,-1])\n",
    "        y_max = max(y_max, averaged_pose[1,-1])\n",
    "        z_min = min(z_min, averaged_pose[2,-1])\n",
    "        z_max = max(z_max, averaged_pose[2,-1])\n",
    "    \n",
    "    ################# GROUND TRUTH OBJECT POSE #################\n",
    "    \n",
    "    \n",
    "    ################# GROUND TRUTH SCENE PLOTTING #################\n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel('X Axis')\n",
    "        ax.set_ylabel('Y Axis')\n",
    "        ax.set_zlabel('Z Axis')\n",
    "        ax.set_xlim((x_min-100, x_max+100))\n",
    "        ax.set_ylim((y_min-100, y_max+100))\n",
    "        ax.set_zlim((z_min-100, z_max+100))\n",
    "        plot_traj(gt_traj, ax, c = 'blue', length=200)\n",
    "\n",
    "        # plotting as poses\n",
    "        for o in range(len(object_pose['1'])):\n",
    "            plot_traj([gt_pose[o]], ax, length=200)\n",
    "\n",
    "\n",
    "        # plotting as ellipsoids and cuboids\n",
    "        for o in range(len(object_pose['1'])):\n",
    "            class_id = str(classes[o])\n",
    "            radii = np.array([model_data[class_id]['size_x'],\n",
    "                              model_data[class_id]['size_y'],\n",
    "                              model_data[class_id]['size_z']])\n",
    "            # plotting as ellipsoids\n",
    "            # plot_ellipsoid(gt_pose[o], radii/2, ax, colors[o])\n",
    "            # plotting as cuboids\n",
    "            plot_cuboid(gt_pose[o], radii, ax, colors[o])\n",
    "\n",
    "        ax.legend(handles=[\n",
    "                Patch(facecolor=c, edgecolor=c, label=dataset_info[str(l)]) for l, c in zip(classes, colors)\n",
    "            ])\n",
    "        ax.grid(False)\n",
    "        plt.savefig(images_save_directory + '/ground_truth_scene.png')\n",
    "        plt.close()\n",
    "        \n",
    "    ################# GROUND TRUTH SCENE PLOTTING #################\n",
    "    \n",
    "    ################# ESTIMATED CAMERA POSE #################\n",
    "    \n",
    "    ## reading output file\n",
    "    if batch:\n",
    "        output_path = dataset + \"/quadric_slam_result/output_batch.json\"\n",
    "    else:\n",
    "        output_path = dataset + \"/quadric_slam_result/output_incre.json\"\n",
    "\n",
    "    with open(output_path, 'r') as file:\n",
    "        output_data = json.load(file)\n",
    "    \n",
    "    ## unaligned camera poses\n",
    "    unaligned_traj = []\n",
    "\n",
    "    for k,v in output_data['poses'].items():\n",
    "        unaligned_traj.append(np.array(output_data['poses'][k]))\n",
    "    \n",
    "    ## unaligned trajectories\n",
    "    unaligned_quad = output_data['quadrics']\n",
    "\n",
    "    for k,v in unaligned_quad.items():\n",
    "        unaligned_quad[k]['pose'] = np.array(v['pose'])\n",
    "        unaligned_quad[k]['centroid'] = np.array(v['centroid'])\n",
    "        unaligned_quad[k]['radii'] = np.abs(np.array(v['radii']))\n",
    "        \n",
    "    # to store the object class label for each quadric key\n",
    "    labels = output_data['labels']\n",
    "    \n",
    "    ## Aligning the estimated camera pose with origin\n",
    "    est_traj_origin = np.linalg.inv(unaligned_traj[0])\n",
    "\n",
    "    origin_aligned_traj = []\n",
    "\n",
    "    for traj in unaligned_traj:\n",
    "        origin_aligned_traj.append(np.dot(est_traj_origin, traj))\n",
    "        \n",
    "    ## Aligning the estimated camera pose with ground truth\n",
    "    aligned_traj = []\n",
    "\n",
    "    for traj in origin_aligned_traj:\n",
    "        aligned_traj.append(np.dot(gt_traj[0], traj))\n",
    "        \n",
    "    ## Aligning the estimated object pose with origin\n",
    "    origin_aligned_quad = unaligned_quad\n",
    "\n",
    "    for k,v in origin_aligned_quad.items():\n",
    "        origin_aligned_quad[k]['pose'] = np.dot(est_traj_origin, v['pose'])\n",
    "        \n",
    "    ## Aligning the estimated object pose with ground truth\n",
    "    aligned_quad = origin_aligned_quad\n",
    "\n",
    "    for k,v in aligned_quad.items():\n",
    "        aligned_quad[k]['pose'] = np.dot(gt_traj[0], v['pose'])\n",
    "        \n",
    "    ################# ESTIMATED TRAJECTORY PLOTTING #################\n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel('X Axis')\n",
    "        ax.set_ylabel('Y Axis')\n",
    "        ax.set_zlabel('Z Axis')\n",
    "        ax.set_xlim((x_min-100, x_max+100))\n",
    "        ax.set_ylim((y_min-100, y_max+100))\n",
    "        ax.set_zlim((z_min-100, z_max+100))\n",
    "\n",
    "        plot_traj(gt_traj, ax, c = 'blue', label=\"ground truth\", length=200)\n",
    "        plot_traj(aligned_traj, ax, c = 'green', label=\"estimated\", length=200)\n",
    "\n",
    "        ax.legend()\n",
    "        ax.grid(False)\n",
    "        plt.savefig(images_save_directory + '/aligned_trajectories.png')\n",
    "        plt.close()\n",
    "    ################# ESTIMATED TRAJECTORY PLOTTING #################\n",
    "    \n",
    "    \n",
    "    ################# ESTIMATED SCENE PLOTTING #################\n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel('X Axis')\n",
    "        ax.set_ylabel('Y Axis')\n",
    "        ax.set_zlabel('Z Axis')\n",
    "        ax.set_xlim((x_min-100, x_max+100))\n",
    "        ax.set_ylim((y_min-100, y_max+100))\n",
    "        ax.set_zlim((z_min-100, z_max+100))\n",
    "\n",
    "        ## plotting trajectories\n",
    "        plot_traj(gt_traj, ax, c = 'blue', label=\"ground truth\", length=200)\n",
    "        plot_traj(aligned_traj, ax, c = 'green', label=\"estimated\", length=200)\n",
    "\n",
    "        # plotting GT object pose as cuboid\n",
    "        for o in range(len(object_pose['1'])):\n",
    "            plot_traj([gt_pose[o]], ax, length=200)\n",
    "\n",
    "            class_id = str(classes[o])\n",
    "            radii = np.array([model_data[class_id]['size_x'],\n",
    "                              model_data[class_id]['size_y'],\n",
    "                              model_data[class_id]['size_z']])\n",
    "            # plotting as ellipsoids\n",
    "            # plot_ellipsoid(gt_pose[o], radii/2, ax, colors[o])\n",
    "            # plotting as cuboids\n",
    "            plot_cuboid(gt_pose[o], radii, ax, colors[o])\n",
    "\n",
    "\n",
    "        # plotting estimated object pose as ellipsoids\n",
    "        for k,v in aligned_quad.items():\n",
    "            plot_traj([v['pose']], ax, length=200)\n",
    "\n",
    "            plot_ellipsoid(v['pose'], v['radii'],\n",
    "                           ax, colors[classes.index(labels[k])])\n",
    "\n",
    "\n",
    "        ax.legend(handles=[\n",
    "                Patch(facecolor=c, edgecolor=c, label=dataset_info[str(l)]) for l, c in zip(classes, colors)\n",
    "            ])\n",
    "        ax.grid(False)\n",
    "        plt.savefig(images_save_directory + '/estimated_scene.png')\n",
    "        plt.close()\n",
    "        \n",
    "    ################# ESTIMATED SCENE PLOTTING #################\n",
    "    \n",
    "    \n",
    "    ################# ERROR METRICS CALCULATION #################\n",
    "    \n",
    "    ####### CAMERA POSE ERRORS #######\n",
    "    ## 1. Root Mean Square Error(RMSE) for Trajectory Deviation (Euclidean Distance)\n",
    "    # Euclidean distance\n",
    "    euc_errors = []\n",
    "\n",
    "    for i in range(len(gt_traj)):\n",
    "        euc_errors.append(euclidean_distance(gt_traj[i][:3, 3], aligned_traj[i][:3, 3]))\n",
    "        \n",
    "    squared_error = [item ** 2 for item in euc_errors]\n",
    "    \n",
    "    mean_squared_error = sum(squared_error)/len(squared_error)\n",
    "    \n",
    "    rmse = math.sqrt(mean_squared_error)\n",
    "    \n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot([i for i in range(len(euc_errors))], euc_errors)\n",
    "        ax.set_xlabel('Camera Frame')\n",
    "        ax.set_ylabel('Euclidean Distance (mm)')\n",
    "        plt.title(\"Trajectory Deviation\")\n",
    "        ax.grid(False)\n",
    "        plt.savefig(images_save_directory + '/trajectory_deviation.png')\n",
    "        plt.close()\n",
    "        \n",
    "    ## 2. Average Rotation Error for Camera Poses\n",
    "    rot_errors_traj = []\n",
    "    \n",
    "    for i in range(len(gt_traj)):\n",
    "        # order is dependent\n",
    "        rot_errors_traj.append(rotation_error_quaternion(matrix_to_quaternion(gt_traj[i]),\n",
    "                                                         matrix_to_quaternion(aligned_traj[i])))\n",
    "        \n",
    "    rot_errors_traj = [value for value in rot_errors_traj if not math.isnan(value)]\n",
    "    \n",
    "    avg_rot_error_traj = sum(rot_errors_traj)/len(rot_errors_traj)\n",
    "    \n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot([i for i in range(len(rot_errors_traj))], rot_errors_traj)\n",
    "        ax.set_xlabel('Camera Frame')\n",
    "        ax.set_ylabel('Rotation error (rad)')\n",
    "        plt.title(\"Rotation Error\")\n",
    "        ax.grid(False)\n",
    "        plt.savefig(images_save_directory + '/trajectory_rotation_error.png')\n",
    "        plt.close()\n",
    "    \n",
    "    ## 3. Disparity Measure by Procrustes Analysis\n",
    "    points_gt = []\n",
    "    points_est = []\n",
    "\n",
    "    for i in range(len(gt_traj)):\n",
    "        points_gt.append(list(gt_traj[i][:3, 3]))\n",
    "        points_est.append(list(aligned_traj[i][:3, 3]))\n",
    "\n",
    "    points_gt = np.array(points_gt)\n",
    "    points_est = np.array(points_est)\n",
    "\n",
    "    set1, set2, disparity = procrustes_analysis(points_gt, points_est)\n",
    "    \n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot(set1[:,0], set1[:,1], set1[:,2], c='r', marker='o', alpha=0.5, label='Ground Truth')\n",
    "        ax.plot(set2[:,0], set2[:,1], set2[:,2], c='b', marker='o', alpha=0.5, label='Estimated')\n",
    "        ax.grid(False)\n",
    "        ax.legend()\n",
    "        plt.title(\"Procrustes Analysis - Normalised and Aligned\")\n",
    "        plt.savefig(images_save_directory + '/procrustes_analysis.png')\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    ## 4. Fréchet Distance\n",
    "    f_dist = frechet_distance(points_gt, points_est)\n",
    "    \n",
    "    ## 5. Chamfer Distance\n",
    "    c_dist = chamfer_distance(points_gt, points_est)\n",
    "    ####### CAMERA POSE ERRORS #######\n",
    "    \n",
    "    ####### OBJECT POSE ERRORS #######\n",
    "    ## keep only 1 object in aligned_quad\n",
    "    ## identify unique keys\n",
    "    seen_integers = []\n",
    "    new_labels = dict()\n",
    "    unique_keys = []\n",
    "    for k,v in labels.items():\n",
    "        if v not in seen_integers:\n",
    "            seen_integers.append(v)\n",
    "            unique_keys.append(k)\n",
    "            new_labels[k] = v\n",
    "    labels = new_labels\n",
    "    ## update the output dictionary\n",
    "    new_aligned_quad = dict()\n",
    "    for k,v in aligned_quad.items():\n",
    "        if k in unique_keys:\n",
    "            new_aligned_quad[k] = v\n",
    "    aligned_quad = new_aligned_quad\n",
    "\n",
    "    ## 1. Average Centroid Error (Euclidean Distance)\n",
    "    # GT centroids\n",
    "    centroids_gt = []\n",
    "    for o in range(len(gt_pose)):\n",
    "        centroids_gt.append(gt_pose[o][:3,3])\n",
    "\n",
    "    # Estimated centroids\n",
    "    centroids_est = []\n",
    "    for k,v in aligned_quad.items():\n",
    "        centroids_est.append(v['pose'][:3,3])\n",
    "\n",
    "    centroid_errors = []\n",
    "\n",
    "    for i in range(len(centroids_gt)):\n",
    "        centroid_errors.append(euclidean_distance(centroids_gt[i], centroids_est[i]))\n",
    "    # average centroid error\n",
    "    avg_cen_err = sum(centroid_errors)/len(centroid_errors)\n",
    "    \n",
    "    \n",
    "    ## 2. Average Rotation Error for Object Poses\n",
    "    # rotation matrix quadrent correction\n",
    "    est_obj_mod_mat = []\n",
    "    \n",
    "    for k,v in aligned_quad.items():\n",
    "        inverse = np.eye(4)\n",
    "        inverse[:3, :3] = v['pose'][:3, :3].T\n",
    "\n",
    "        # Convert the rotation matrix to a Rotation object\n",
    "        r = Rotation.from_matrix(inverse[:3, :3])\n",
    "\n",
    "        # Convert to Euler angles (XYZ rotation order)\n",
    "        euler_angles = r.as_euler('xyz', degrees=True)\n",
    "\n",
    "        # Extract individual angles\n",
    "        alpha = threshold_to_closest_multiple_of_90(euler_angles[0])  # X-axis rotation\n",
    "        beta = threshold_to_closest_multiple_of_90(euler_angles[1])   # Y-axis rotation\n",
    "        gamma = threshold_to_closest_multiple_of_90(euler_angles[2])  # Z-axis rotation\n",
    "\n",
    "        rotation_transform = np.eye(4)\n",
    "        # Create a Rotation matrix from Euler angles (XYZ rotation order)\n",
    "        r = Rotation.from_euler('xyz', [alpha, beta, gamma], degrees=True)\n",
    "        rotation_transform[:3, :3] = r.as_matrix()\n",
    "\n",
    "        est_obj_mod_mat.append(np.dot(v['pose'], rotation_transform))\n",
    "        \n",
    "    # calculating the error\n",
    "    rot_errors_obj = []\n",
    "    \n",
    "\n",
    "    for o in range(len(gt_pose)):\n",
    "        # order is dependent\n",
    "        rot_errors_obj.append(rotation_error_quaternion(matrix_to_quaternion(gt_pose[o]),\n",
    "                                                        matrix_to_quaternion(est_obj_mod_mat[o])))\n",
    "\n",
    "    \n",
    "    avg_rot_error_obj = sum(rot_errors_obj)/ len(rot_errors_obj)\n",
    "    \n",
    "    \n",
    "    ## 3. Percentage of Intersection Volume\n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel('X Axis')\n",
    "        ax.set_ylabel('Y Axis')\n",
    "        ax.set_zlabel('Z Axis')\n",
    "        ax.grid(False)\n",
    "        ax.legend(handles=[\n",
    "            Patch(facecolor=c, edgecolor=c, label=dataset_info[str(l)]) for l, c in zip(classes, colors)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    # to ensure same particles are generated for oa-slam and quadricslam\n",
    "    np.random.seed(50)\n",
    "\n",
    "    ## The higher the nmber of points, the better is the monte-carlo approximation\n",
    "    num_points = 10000\n",
    "\n",
    "    overlap_cuboid = [] # percentage of overlapping points\n",
    "\n",
    "    volume_cuboid = []\n",
    "    volume_est_ellipsoid = []\n",
    "\n",
    "    o = 0\n",
    "\n",
    "    for k,v in aligned_quad.items():\n",
    "        \n",
    "        class_id = str(classes[o])\n",
    "        # volume of a cuboid\n",
    "        cube_dimensions = np.array([model_data[class_id]['size_x'],\n",
    "                                    model_data[class_id]['size_y'],\n",
    "                                    model_data[class_id]['size_z']])\n",
    "        # length * breadth * height\n",
    "        volume_cuboid.append(np.prod(cube_dimensions))\n",
    "\n",
    "        # volume of an ellipsoid\n",
    "        volume_est_ellipsoid.append((4/3) * np.pi * (np.prod(v['radii'])))\n",
    "\n",
    "        # generate points within the cuboid\n",
    "        points_within_cuboid = generate_points_within_cuboid(gt_pose[o][:3,3], cube_dimensions, \n",
    "                                                             gt_pose[o][:3,:3], num_points)\n",
    "        points = np.array(points_within_cuboid)\n",
    "\n",
    "        # check if the point is within the ellipsoid\n",
    "        inside_est_ellipsoid = 0\n",
    "\n",
    "        for i in range(len(points)):\n",
    "            if is_point_inside_ellipsoid(points[i], v['pose'][:3,3],\n",
    "                                         v['radii'], v['pose'][:3,:3]):\n",
    "                inside_est_ellipsoid+=1\n",
    "\n",
    "        overlap_cuboid.append(inside_est_ellipsoid / num_points)\n",
    "        \n",
    "        if plottings:\n",
    "            ### Plotting the experiment ###\n",
    "            # scatter the points within the plot\n",
    "            ax.scatter(points[:, 0], points[:, 1], points[:, 2], c='k', s=0.1)\n",
    "            # plot the GT cuboid\n",
    "            plot_cuboid(gt_pose[o], cube_dimensions, ax, colors[classes.index(classes[o])])\n",
    "            # plot the estimated ellipsoid\n",
    "            plot_ellipsoid(v['pose'], v['radii'], ax, colors[classes.index(classes[o])])\n",
    "        \n",
    "        o+=1\n",
    "    \n",
    "    if plottings:\n",
    "        plt.title(\"Monte-Carlo Sample Point Generation\")\n",
    "        plt.savefig(images_save_directory + '/intersection_volume.png')\n",
    "        plt.close()\n",
    "        \n",
    "    intersection_percent = [] # percentage of intersection\n",
    "    for i in range(len(overlap_cuboid)):\n",
    "        intersection_percent.append((2*volume_cuboid[i]*overlap_cuboid[i]*100)/(volume_cuboid[i]+volume_est_ellipsoid[i]))\n",
    "        \n",
    "    avg_int_per = sum(intersection_percent)/len(intersection_percent)\n",
    "    \n",
    "    ## 4. Percentage of Intersection Volume\n",
    "    if plottings:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel('X Axis')\n",
    "        ax.set_ylabel('Y Axis')\n",
    "        ax.set_zlabel('Z Axis')\n",
    "        ax.grid(False)\n",
    "        ax.legend(handles=[\n",
    "            Patch(facecolor=c, edgecolor=c, label=dataset_info[str(l)]) for l, c in zip(classes, colors)\n",
    "        ])\n",
    "\n",
    "    overlap_cuboid = [] # percentage of overlapping points\n",
    "\n",
    "    volume_cuboid = []\n",
    "    volume_est_ellipsoid = []\n",
    "\n",
    "    o = 0\n",
    "\n",
    "    for k,v in aligned_quad.items():\n",
    "        \n",
    "        class_id = str(classes[o])\n",
    "        # volume of a cuboid\n",
    "        cube_dimensions = np.array([model_data[class_id]['size_x'],\n",
    "                                    model_data[class_id]['size_y'],\n",
    "                                    model_data[class_id]['size_z']])\n",
    "        # length * breadth * height\n",
    "        volume_cuboid.append(np.prod(cube_dimensions))\n",
    "\n",
    "        # volume of an ellipsoid\n",
    "        volume_est_ellipsoid.append((4/3) * np.pi * (np.prod(v['radii'])))\n",
    "\n",
    "        # generate points within the cuboid\n",
    "        points_within_cuboid = generate_points_within_cuboid(gt_pose[o][:3,3], cube_dimensions, \n",
    "                                                             gt_pose[o][:3,:3], num_points)\n",
    "        points = np.array(points_within_cuboid)\n",
    "\n",
    "        # check if the point is within the ellipsoid\n",
    "        inside_est_ellipsoid = 0\n",
    "        \n",
    "        \n",
    "        # Estimated object aligning with GT object\n",
    "        gt_inv = np.linalg.inv(gt_pose[o])\n",
    "        T_rel = np.dot(gt_inv, v['pose'])\n",
    "        aligned_est = np.dot(v['pose'], np.linalg.inv(T_rel)) ## NEW POSE\n",
    "        # Now the length, breadth and height may interchange.\n",
    "        sorted_indices = np.argsort(cube_dimensions)\n",
    "        sorted_array = np.sort(v['radii'])\n",
    "        aligned_size = np.ones(3)\n",
    "        for j in range(3):\n",
    "            aligned_size[sorted_indices[j]] = sorted_array[j] ## NEW RADIUS\n",
    "            \n",
    "\n",
    "        for i in range(len(points)):\n",
    "            if is_point_inside_ellipsoid(points[i], aligned_est[:3,3],\n",
    "                                         aligned_size, aligned_est[:3,:3]):\n",
    "                inside_est_ellipsoid+=1\n",
    "\n",
    "        overlap_cuboid.append(inside_est_ellipsoid / num_points)\n",
    "        \n",
    "        if plottings:\n",
    "            ### Plotting the experiment ###\n",
    "            # scatter the points within the plot\n",
    "            ax.scatter(points[:, 0], points[:, 1], points[:, 2], c='k', s=0.1)\n",
    "            # plot the GT cuboid\n",
    "            plot_cuboid(gt_pose[o], cube_dimensions, ax, colors[classes.index(classes[o])])\n",
    "            # plot the estimated ellipsoid\n",
    "            plot_ellipsoid(aligned_est, aligned_size,\n",
    "                           ax, colors[classes.index(classes[o])])\n",
    "        \n",
    "        o+=1\n",
    "    \n",
    "    if plottings:\n",
    "        plt.title(\"Monte-Carlo Sample Point Generation After Alignment\")\n",
    "        plt.savefig(images_save_directory + '/intersection_volume_after_alignment.png')\n",
    "        plt.close()\n",
    "        \n",
    "    intersection_percent_aligned = [] # percentage of intersection\n",
    "    for i in range(len(overlap_cuboid)):\n",
    "        intersection_percent_aligned.append((2*volume_cuboid[i]*overlap_cuboid[i]*100)/(volume_cuboid[i]+volume_est_ellipsoid[i]))\n",
    "        \n",
    "    avg_int_per_aligned = sum(intersection_percent_aligned)/len(intersection_percent_aligned)\n",
    "    \n",
    "    \n",
    "    ####### OBJECT POSE ERRORS #######\n",
    "    \n",
    "    ################# ERROR METRICS CALCULATION #################\n",
    "    \n",
    "    ################# EXPORTING TO JSON #################\n",
    "    labels = [dataset_info[str(l)] for l in classes]\n",
    "    \n",
    "    export_data = {'camera_pose': {\n",
    "                                   'euc_error': euc_errors,\n",
    "                                   'root_mean_square_error': rmse,\n",
    "                                   'rotation_error': rot_errors_traj,\n",
    "                                   'average_rotation_error': avg_rot_error_traj,\n",
    "                                   'disparity': disparity,\n",
    "                                   'frechet_distance': f_dist,\n",
    "                                   'chamfer_distance': c_dist\n",
    "                                    },\n",
    "                   'object_pose': {\n",
    "                                   'centroid_error': centroid_errors,\n",
    "                                   'average_centroid_error': avg_cen_err,\n",
    "                                   'rotation_error': rot_errors_obj,\n",
    "                                   'average_rotation_error': avg_rot_error_obj,\n",
    "                                   'volume_of_intersection': intersection_percent,\n",
    "                                   'average_volume_of_intersection': avg_int_per,\n",
    "                                   'volume_of_intersection_aligned': intersection_percent_aligned,\n",
    "                                   'average_volume_of_intersection_aligned': avg_int_per_aligned,\n",
    "                                   'labels': labels\n",
    "                                    }\n",
    "                   }\n",
    "    if batch:\n",
    "        export_path = os.path.join(dataset, 'quadric_slam_result/error_metrics_batch.json')\n",
    "    else:\n",
    "        export_path = os.path.join(dataset, 'quadric_slam_result/error_metrics_incre.json')\n",
    "        \n",
    "    with open(export_path, \"w\") as json_file:\n",
    "        json.dump(export_data, json_file, indent=4)  # indent for pretty formatting\n",
    "    ################# EXPORTING TO JSON #################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b179f7",
   "metadata": {},
   "source": [
    "# Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ae90466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed:  /home/allen/Desktop/RnD_Github/AllenIsaacRnD/dataset/000001\n"
     ]
    }
   ],
   "source": [
    "##### Dataset path\n",
    "dataset_path = \"/home/allen/Desktop/RnD_Github/AllenIsaacRnD/dataset/\"\n",
    "\n",
    "##### Extracting the absolute path for all the datasets\n",
    "datasets_path = []\n",
    "\n",
    "for folder in os.listdir(dataset_path):\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "\n",
    "    if os.path.isdir(folder_path) and not folder.startswith('.'):\n",
    "        datasets_path.append(folder_path)\n",
    "        \n",
    "datasets_path.sort()\n",
    "        \n",
    "##### Processing each dataset\n",
    "for dataset in datasets_path:\n",
    "    # dataset -> path to the dataset folder\n",
    "    # plottings -> the bool that controls the plots to be saved or not\n",
    "    # batch -> if batch, then read the batch output file\n",
    "    postprocessing(dataset, True, True)\n",
    "    print(\"Processed: \", dataset)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7aadea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
